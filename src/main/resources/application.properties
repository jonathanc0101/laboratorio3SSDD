server.servlet.context-path=/api

## default connection pool
spring.datasource.hikari.connectionTimeout=20000
spring.datasource.hikari.maximumPoolSize=5
spring.jpa.generate-ddl=true

## PostgreSQL
spring.datasource.url=${SPRING_DATASOURCE_URL}
spring.datasource.username=${SPRING_DATASOURCE_USER}
spring.datasource.password=${SPRING_DATASOURCE_PASSWORD}

spring.datasource.hikari.schema=public

logging.level.org.springframework.web.filter.CommonsRequestLoggingFilter=DEBUG
logging.level.bordero.client.LoggingInterceptor=DEBUG

bordero.server.id=${BORDERO_SERVER_ID}

# Required connection configs for Kafka producer, consumer, and admin
spring.kafka.properties.bootstrap.servers=broker:9092

# Best practice for higher availability in Apache Kafka clients prior to 3.0
spring.kafka.properties.session.timeout.ms=45000


spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.IntegerSerializer
spring.kafka.producer.value-serializer=bordero.backend.kafka.serdes.EventSerializer

spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.IntegerDeserializer
spring.kafka.consumer.value-deserializer=bordero.backend.kafka.serdes.EventDeserializer

# Required connection configs for Confluent Cloud Schema Registry
#spring.kafka.properties.basic.auth.credentials.source=USER_INFO
#spring.kafka.properties.basic.auth.user.info={{ SR_API_KEY }}:{{ SR_API_SECRET }}
#spring.kafka.properties.schema.registry.url=https://{{ SR_ENDPOINT }}
